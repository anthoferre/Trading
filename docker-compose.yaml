
volumes:
  trading_models:
  mlruns:
    driver: local

services:
  # A. Service pour l'Entraînement et la Préparation des Données
  pipeline:
    build: 
      context: .
      dockerfile: Dockerfile.pipeline 
    image: trading-pipeline:latest
    volumes:
      - trading_models:/app/models 
      - ./config:/app/config
      - mlruns:/app/mlruns
    restart: "on-failure"    
    entrypoint: ["python", "run_pipeline.py"] 

  # B. Service pour l'API (Inférence en temps réel)
  api:
    build: 
      context: .
      dockerfile: Dockerfile.api 
    image: trading-api:latest
    ports:
      - "8000:80"
    volumes:
      - trading_models:/app/models
    restart: always
    command: uvicorn api.main:app --host 0.0.0.0 --port 80

  # C. MLFlow
  mlflow-server:
    image: trading-pipeline:latest
    container_name: mlflow_tracker
    ports:
      - "5000:5000"
    volumes:
      - mlruns:/mlruns
      - ./config:/app/config
    environment:
      - MLFLOW_TRACKING_URI=file:/mlruns
    command: mlflow server --backend-store-uri file:/mlruns --host 0.0.0.0 --port 5000